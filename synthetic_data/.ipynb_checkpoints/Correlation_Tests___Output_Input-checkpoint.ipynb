{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b78e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import causallearn\n",
    "from causallearn.utils.cit import *\n",
    "from causallearn.graph.GraphClass import CausalGraph\n",
    "import pandas as pd\n",
    "from itertools import combinations, permutations\n",
    "from numpy import ndarray\n",
    "from typing import Dict, List, Tuple\n",
    "from causallearn.utils.cit import fisherz\n",
    "import random\n",
    "import time\n",
    "\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe23cf8",
   "metadata": {},
   "source": [
    "# Initialize Dataset (Sample num_traj trajectories of length T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2c292ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.6\n",
    "num_states = 50\n",
    "num_inputs = 20\n",
    "num_outputs = 25\n",
    "\n",
    "A = np.random.normal(0,1, (num_states, num_states))\n",
    "B = np.ones((num_states, num_inputs)) * beta\n",
    "C = np.random.normal(0,1, (num_outputs, num_states))\n",
    "T = 2\n",
    "num_traj = 20000\n",
    "# num_traj = 10000\n",
    "\n",
    "for traj_id in range(num_traj):\n",
    "    x_vec = np.zeros((num_states, T))\n",
    "    y_vec = np.zeros((num_outputs, T))\n",
    "    x_vec[:, 0] = np.random.randn(num_states)\n",
    "    y_vec[:, 0] = C @ x_vec[:, 0]\n",
    "    \n",
    "    u_vec = np.random.randn(num_inputs, T)\n",
    "    #w_vec = np.random.randn(2,T) * np.sqrt(1 - alpha**2 - beta**2)\n",
    "    \n",
    "    for t in range(T-1):\n",
    "    #     print(t)\n",
    "        x_vec[:, t+1] = A @ x_vec[:, t] + B @ u_vec[:,t] #+ w_vec[:, t]\n",
    "        y_vec[:, t+1] = C @ x_vec[:, t+1]\n",
    "    \n",
    "    y_u_vec = np.block([[y_vec], [u_vec]])\n",
    "    \n",
    "    if traj_id == 0:\n",
    "        traj_dataset = np.zeros((num_traj, y_u_vec.shape[0], y_u_vec.shape[1]))\n",
    "        traj_dataset[0, :, :] = y_u_vec\n",
    "    else:\n",
    "        traj_dataset[traj_id, :, :] = y_u_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f522cdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 45, 2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plt.plot(traj_dataset)\n",
    "traj_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "de10d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert traj_dataset.shape == (num_traj, num_outputs + num_inputs, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "43cc09bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_traj, num_quantities, _ = traj_dataset.shape\n",
    "# num_quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60427eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92d45d4e",
   "metadata": {},
   "source": [
    "# Modified PC Algorithm for Learning Number of Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dde5f18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_test(data, m, rho_m):\n",
    "    num_traj, num_quantities, _ = data.shape\n",
    "    input_indices = []\n",
    "    \n",
    "    for i in range(num_quantities):\n",
    "        node_indices_to_test = np.random.choice(num_quantities, m)\n",
    "        for count, j in enumerate(node_indices_to_test):\n",
    "            corr = sp.stats.pearsonr(traj_dataset[:, j, 0], traj_dataset[:, i, 1])[0]\n",
    "            if corr >= rho_m:\n",
    "                break\n",
    "            if count == m-1:\n",
    "                input_indices.append(i)\n",
    "    \n",
    "    return input_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2da9905",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3b40940f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "count_m: 0\n",
      "count_rho 0\n",
      "count_rho 1\n",
      "count_rho 2\n",
      "count_rho 3\n",
      "count_rho 4\n",
      "\n",
      "\n",
      "count_m: 1\n",
      "count_rho 0\n",
      "count_rho 1\n",
      "count_rho 2\n",
      "count_rho 3\n",
      "count_rho 4\n",
      "\n",
      "\n",
      "count_m: 2\n",
      "count_rho 0\n",
      "count_rho 1\n",
      "count_rho 2\n",
      "count_rho 3\n",
      "count_rho 4\n",
      "\n",
      "\n",
      "count_m: 3\n",
      "count_rho 0\n",
      "count_rho 1\n",
      "count_rho 2\n",
      "count_rho 3\n",
      "count_rho 4\n",
      "\n",
      "\n",
      "count_m: 4\n",
      "count_rho 0\n",
      "count_rho 1\n",
      "count_rho 2\n",
      "count_rho 3\n",
      "count_rho 4\n",
      "\n",
      "\n",
      "count_m: 5\n",
      "count_rho 0\n",
      "count_rho 1\n",
      "count_rho 2\n",
      "count_rho 3\n",
      "count_rho 4\n",
      "\n",
      "\n",
      "count_m: 6\n",
      "count_rho 0\n",
      "count_rho 1\n",
      "count_rho 2\n",
      "count_rho 3\n",
      "count_rho 4\n",
      "\n",
      "\n",
      "count_m: 7\n",
      "count_rho 0\n",
      "count_rho 1\n",
      "count_rho 2\n",
      "count_rho 3\n",
      "count_rho 4\n",
      "\n",
      "\n",
      "count_m: 8\n",
      "count_rho 0\n",
      "count_rho 1\n",
      "count_rho 2\n",
      "count_rho 3\n",
      "count_rho 4\n",
      "\n",
      "\n",
      "count_m: 9\n",
      "count_rho 0\n",
      "count_rho 1\n",
      "count_rho 2\n",
      "count_rho 3\n",
      "count_rho 4\n",
      "\n",
      "Time: 88.21803402900696\n"
     ]
    }
   ],
   "source": [
    "begin_time = time.time()\n",
    "\n",
    "m_list = [2*x + 2 for x in list(range(10))]\n",
    "rho_min_list = [x * 0.01 + 0.01 for x in list(range(5))]\n",
    "input_indices_true = list(range(num_outputs, num_outputs + num_inputs))\n",
    "num_trials = 10\n",
    "\n",
    "false_positive_avg_array = np.zeros((len(m_list), len(rho_min_list)))\n",
    "missed_detection_avg_array = np.zeros((len(m_list), len(rho_min_list)))\n",
    "\n",
    "for count_m, m in enumerate(m_list):\n",
    "    print(\"\\n\")\n",
    "    print(\"count_m:\", count_m)\n",
    "    for count_rho, rho_min in enumerate(rho_min_list):\n",
    "        print(\"count_rho\", count_rho)\n",
    "        false_positive_quantity_list = []\n",
    "        missed_detection_quantity_list = []\n",
    "        for trial_id in range(num_trials):\n",
    "            input_indices_est = correlation_test(traj_dataset, m, rho_min)\n",
    "            false_positive_quantity_list.append(len([k for k in input_indices_est if k not in input_indices_true]))\n",
    "            missed_detection_quantity_list.append(len([k for k in input_indices_true if k not in input_indices_est]))\n",
    "        false_positive_avg_array[count_m, count_rho] = sum(false_positive_quantity_list)/len(false_positive_quantity_list)\n",
    "        missed_detection_avg_array[count_m, count_rho] = sum(missed_detection_quantity_list)/len(missed_detection_quantity_list)\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"\\nTime:\", end_time - begin_time)\n",
    "\n",
    "# print(correlation_test(traj_dataset, 10, 0.05))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "98f1ee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_indices_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "18e742e0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.   9.8  9.6 10.8 11.5]\n",
      " [ 4.2  4.7  6.6  5.8  7. ]\n",
      " [ 2.   2.5  4.1  4.2  4. ]\n",
      " [ 0.8  1.8  1.9  2.7  3.1]\n",
      " [ 0.7  1.   1.3  1.9  2.4]\n",
      " [ 0.3  0.6  0.7  1.   1.1]\n",
      " [ 0.4  0.3  0.4  0.6  1.1]\n",
      " [ 0.3  0.1  0.4  0.3  0.6]\n",
      " [ 0.   0.2  0.5  0.2  0.5]\n",
      " [ 0.1  0.   0.1  0.1  0.2]]\n",
      "[[ 3.8  0.1  0.   0.   0. ]\n",
      " [ 6.1  0.2  0.   0.   0. ]\n",
      " [ 8.7  0.1  0.   0.   0. ]\n",
      " [ 9.   0.2  0.   0.   0. ]\n",
      " [10.9  0.1  0.   0.   0. ]\n",
      " [11.6  0.2  0.   0.   0. ]\n",
      " [13.9  0.1  0.   0.   0. ]\n",
      " [13.5  0.2  0.   0.   0. ]\n",
      " [15.5  0.4  0.   0.   0. ]\n",
      " [15.6  0.3  0.   0.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "print(false_positive_avg_array)\n",
    "print(missed_detection_avg_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a6b27da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 20\n",
    "rho_min = 0.02\n",
    "\n",
    "# for i in range(num_quantities):\n",
    "#     print(\"\\ni:\", i)\n",
    "#     for j in range(num_quantities):\n",
    "#         print(\"j:\", j, \"corr:\", sp.stats.pearsonr(traj_dataset[:, j, 0], traj_dataset[:, i, 1])[0])\n",
    "\n",
    "# print(traj_dataset[:, 10, 0])\n",
    "# print(traj_dataset[:, 15, 1])\n",
    "\n",
    "correlation_test(traj_dataset, m, rho_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460668a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "286cebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results:\n",
    "\n",
    "path_directory = \"/Users/chih-yuanchiu/Desktop/Code/Causality_Time_Series/data/\"\n",
    "\n",
    "path_file = path_directory + \"false_positive_avg_array.csv\"\n",
    "false_positive_avg_array_pd = pd.DataFrame(false_positive_avg_array)\n",
    "false_positive_avg_array_pd.to_csv(path_file, index=False)\n",
    "\n",
    "path_file = path_directory + \"missed_detection_avg_array.csv\"\n",
    "missed_detection_avg_array_pd = pd.DataFrame(missed_detection_avg_array)\n",
    "missed_detection_avg_array_pd.to_csv(path_file, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05784d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0ddff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4005027d",
   "metadata": {},
   "source": [
    "# Kshitij's algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f004efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sample_corr(data,i,j, num_samples):\n",
    "    avg_t_plus = (1/num_samples)*data[:,i].sum()\n",
    "    avg_t = (1/num_samples)*data[:,j].sum()\n",
    "    diff_t_plus = data[:, i] - avg_t_plus\n",
    "    diff_t = data[:,j] - avg_t_plus\n",
    "    diff_t_plus_sq = (diff_t_plus**2).sum()\n",
    "    diff_t_sq = (diff_t**2).sum()\n",
    "    corr = (np.dot(diff_t_plus, diff_t))/np.sqrt((diff_t_plus_sq*diff_t_sq))\n",
    "    return corr\n",
    "\n",
    "def modified_pc(data, m, num_samples, num_observations, rho_m):\n",
    "    input_set = []\n",
    "    for i in range(data.shape[1]):\n",
    "        subset = np.array(random.sample(list(range(data.shape[1])), m))\n",
    "        for j in subset:\n",
    "            rho_m_hat = compute_sample_corr(data, i,j, num_samples)\n",
    "            if abs(rho_m_hat) >= 0.5*rho_m:\n",
    "                break \n",
    "            if j == subset[-1]:\n",
    "                input_set.append(i)\n",
    "    return input_set\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f10657e",
   "metadata": {},
   "source": [
    "# Scratch Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67407d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_1 = [3, 4, 5]\n",
    "# list_2 = [4, 5, 6]\n",
    "\n",
    "# list_1_not_2 = [k for k in list_1 if k not in list_2]\n",
    "# list_2_not_1 = [k for k in list_2 if k not in list_1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
